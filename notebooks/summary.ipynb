{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from modules import common, chapter_08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(28 * 28,))\n",
    "x = keras.layers.Rescaling(1.0 / 255)(i)\n",
    "x = keras.layers.Dense(units=32, kernel_regularizer=keras.regularizers.L2(l2=0.002), activation=tf.nn.relu)(x)\n",
    "o = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "model.summary()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    verbose=False,\n",
    ")\n",
    "common.plot(data=[history], labels=[\"mnist\"])\n",
    "loss, accuracy = model.evaluate(x=x_test, y=y_test, verbose=False)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy * 100)\n",
    "y_pred = model.predict(x=x_test, verbose=False)\n",
    "for ground, predict in zip(y_test[:5], y_pred[:5]):\n",
    "    print(\"Ground: \", ground)\n",
    "    print(\"Predict: \", predict.argmax())\n",
    "    print(\"Confidence: \", predict.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "B = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(np.tensordot(A, B))\n",
    "print(np.dot(A, B))\n",
    "print(A * B)\n",
    "# Translation: [x y] + [xt yt]\n",
    "# Rotation: [x y] * [[cos_theta, -sin_theta], [cos_theta, sin_theta]]\n",
    "# Affine: mx + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 03**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "class LCTF:\n",
    "    def __init__(self):\n",
    "        self.w = tf.Variable(initial_value=np.random.uniform(size=(2, 1)))\n",
    "        self.b = tf.Variable(initial_value=np.zeros(shape=(1,)))\n",
    "        self.n = 0.001\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Forward Propagation\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = tf.matmul(x, self.w) + self.b\n",
    "            loss = tf.reduce_mean(tf.square(y - y_pred))\n",
    "        # Back Propagation\n",
    "        gw, gb = tape.gradient(loss, [self.w, self.b])\n",
    "        self.w -= self.n * gw\n",
    "        self.b -= self.n * gb\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        y_pred = tf.matmul(x, self.w) + self.b\n",
    "        loss = tf.reduce_mean(tf.square(y - y_pred))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        return tf.matmul(x, self.w) + self.b\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "class LCKeras:\n",
    "    def __init__(self):\n",
    "        self.w = tf.Variable(initial_value=np.random.uniform(size=(2, 1)))\n",
    "        self.b = tf.Variable(initial_value=np.zeros(shape=(1,)))\n",
    "        self.n = 0.001\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "        self.optimizer_fn = keras.optimizers.RMSprop()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Forward Propagation\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = tf.matmul(x, self.w) + self.b\n",
    "            loss = self.loss_fn(y, y_pred)\n",
    "        # Back Propagation\n",
    "        gradient = tape.gradient(loss, [self.w, self.b])\n",
    "        self.optimizer_fn.apply_gradients(zip(gradient, [self.w, self.b]))\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        y_pred = tf.matmul(x, self.w) + self.b\n",
    "        loss = tf.reduce_mean(tf.square(y - y_pred))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        return tf.matmul(x, self.w) + self.b\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "class LCKerasv2:\n",
    "    def __init__(self):\n",
    "        i = keras.Input(shape=(2, 1))\n",
    "        x = keras.layers.Rescaling(1.0 / 255)(i)\n",
    "        o = keras.layers.Dense(units=1, activation=None)(x)\n",
    "        self.model = keras.Model(inputs=i, outputs=o)\n",
    "        self.n = 0.001\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "        self.optimizer_fn = keras.optimizers.RMSprop()\n",
    "\n",
    "    def fit(self, model, x, y):\n",
    "        history = model.fit(x=x, y=y, validation_split=0.3, verbose=False, batch_size=512, epochs=10)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, model, x, y):\n",
    "        loss, accuracy = model.evaluate(x=x, y=y, verbose=False)\n",
    "        return loss, accuracy\n",
    "\n",
    "    def predict(self, model, x):\n",
    "        return model.predict(x=x, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 04**\n",
    "\n",
    "- IMDB: Binary Classification\n",
    "- Reuters: Multi-class Single-label classification\n",
    "- Boston: Non-linear scalar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(data, num_words):\n",
    "    output = np.zeros(shape=(data.shape[0], num_words))\n",
    "    for index, value in enumerate(data):\n",
    "        output[index][value] = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "def holdout(x, y, validation_split=0.3):\n",
    "    val_size = int(x.shape[0] * validation_split)\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    x, y = x[indices], y[indices]\n",
    "    x_val, y_val = x[:val_size], y[:val_size]\n",
    "    x_train, y_train = x[val_size:], y[val_size:]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "num_words = 10000\n",
    "imdb = keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "x_train, x_test = encoding(x_train, num_words), encoding(x_test, num_words)\n",
    "indices = np.random.permutation(x_train.shape[0])\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(num_words,))\n",
    "x = keras.layers.Dense(units=32, activation=tf.nn.relu)(i)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=0.3,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    verbose=False,\n",
    ")\n",
    "common.plot(data=[history], labels=[\"imdb\"])\n",
    "loss, accuracy = model.evaluate(x=x_test[:3], y=y_test[:3], verbose=False)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "y_pred = model.predict(x=x_test, verbose=False)\n",
    "for ground, predict in zip(y_test[:3], y_pred[:3]):\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Ground: \", True if ground == 1 else False)\n",
    "    print(\"Predict: \", True if predict >= 0.5 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-class Single-label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "num_words = 10000\n",
    "reuters = keras.datasets.reuters\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words)\n",
    "x_train = encoding(x_train, num_words)\n",
    "x_test = encoding(x_test, num_words)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "indices = np.random.permutation(x_train.shape[0])\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(num_words,))\n",
    "x = keras.layers.Dense(units=32, activation=tf.nn.relu)(i)\n",
    "o = keras.layers.Dense(units=46, activation=tf.nn.softmax)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=0.3,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    verbose=False,\n",
    ")\n",
    "common.plot(data=[history], labels=[\"imdb\"])\n",
    "loss, accuracy = model.evaluate(x=x_test, y=y_test, verbose=False)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "y_pred = model.predict(x=x_test, verbose=False)\n",
    "for ground, predict in zip(y_train[:10], y_pred[:10]):\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"Ground: \", ground)\n",
    "    print(\"Predict: \", predict.argmax())\n",
    "    print(\"Confidence: \", predict.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear Scalar regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "boston_housing = keras.datasets.boston_housing\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "mean = x_train.mean()\n",
    "x_train -= mean\n",
    "std = x_train.std()\n",
    "x_train /= std\n",
    "x_test -= mean\n",
    "x_test /= std\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(13))\n",
    "x = keras.layers.Dense(units=32, activation=tf.nn.relu)(i)\n",
    "o = keras.layers.Dense(units=1, activation=None)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val = holdout(x_train, y_train)\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    verbose=False,\n",
    ")\n",
    "common.plot(data=[history], labels=[\"boston\"], window_titles=[\"MSE\", \"MAE\"])\n",
    "mse, mae = model.evaluate(x=x_test, y=y_test, verbose=False)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"MAE: \", mae)\n",
    "y_pred = model.predict(x=x_test, verbose=False)\n",
    "for ground, predict in zip(y_test[:3], y_pred[:3]):\n",
    "    print(\"Ground: \", ground)\n",
    "    print(\"Predict: \", predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "white_noise = np.random.random(size=(x_train.shape[0], 10))\n",
    "zero_channel = np.zeros(shape=(x_train.shape[0], 10))\n",
    "x_train_white = np.concatenate([x_train, white_noise], axis=1)\n",
    "x_train_zero = np.concatenate([x_train, zero_channel], axis=1)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(13))\n",
    "x = keras.layers.Dense(units=32, kernel_regularizer=keras.regularizers.L2(l2=0.002), activation=tf.nn.relu)(i)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 07**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "num_samples = 1000\n",
    "num_text = 100\n",
    "num_tags = 10\n",
    "num_departments = 10\n",
    "num_difficulties = 5\n",
    "num_priority = 1\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "I_title = np.random.randint(low=0, high=num_text, size=(num_samples, num_text))\n",
    "I_text = np.random.randint(low=0, high=num_text, size=(num_samples, num_text))\n",
    "I_tags = np.random.randint(low=0, high=num_tags, size=(num_samples, num_tags))\n",
    "O_departments = np.random.randint(low=0, high=num_departments, size=(num_samples, num_departments))\n",
    "O_difficulties = np.random.randint(low=0, high=num_difficulties, size=(num_samples, num_difficulties))\n",
    "O_priorities = np.random.random(size=(num_samples, num_priority))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "L_title = keras.Input(shape=(num_text), name=\"L_title\")\n",
    "L_text = keras.Input(shape=(num_text), name=\"L_text\")\n",
    "L_tags = keras.Input(shape=(num_tags), name=\"L_tags\")\n",
    "i = keras.layers.Concatenate()([L_title, L_text, L_tags])\n",
    "x = keras.layers.Dense(units=32, activation=tf.nn.relu)(i)\n",
    "L_departments = keras.layers.Dense(units=num_departments, activation=tf.nn.softmax, name=\"L_departments\")(x)\n",
    "L_difficulties = keras.layers.Dense(units=num_difficulties, activation=tf.nn.softmax, name=\"L_difficulties\")(x)\n",
    "model = keras.Model(inputs=[L_title, L_text, L_tags], outputs=[L_departments, L_difficulties])\n",
    "features = model.layers[4].output\n",
    "L_priorities = keras.layers.Dense(units=1, activation=tf.nn.sigmoid, name=\"L_priorities\")(features)\n",
    "model = keras.Model(inputs=[L_title, L_text, L_tags], outputs=[L_departments, L_difficulties, L_priorities])\n",
    "keras.utils.plot_model(model, \"../resources/model.png\", show_shapes=True, dpi=64)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss={\n",
    "        \"L_departments\": keras.losses.CategoricalCrossentropy(),\n",
    "        \"L_difficulties\": keras.losses.CategoricalCrossentropy(),\n",
    "        \"L_priorities\": keras.losses.MeanSquaredError(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"L_departments\": [keras.metrics.CategoricalAccuracy()],\n",
    "        \"L_difficulties\": [keras.metrics.CategoricalAccuracy()],\n",
    "        \"L_priorities\": [keras.metrics.MeanAbsoluteError()],\n",
    "    },\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    ")\n",
    "model.fit(\n",
    "    x={\"L_title\": I_title, \"L_text\": I_text, \"L_tags\": I_tags},\n",
    "    y={\"L_departments\": O_departments, \"L_difficulties\": O_difficulties, \"L_priorities\": O_priorities},\n",
    "    validation_split=0.3,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    verbose=False,\n",
    ")\n",
    "evaluation = model.evaluate(\n",
    "    x={\"L_title\": I_title, \"L_text\": I_text, \"L_tags\": I_tags},\n",
    "    y={\"L_departments\": O_departments, \"L_difficulties\": O_difficulties, \"L_priorities\": O_priorities},\n",
    "    verbose=False,\n",
    ")\n",
    "y_pred = model.predict(\n",
    "    x={\"L_title\": I_title, \"L_text\": I_text, \"L_tags\": I_tags},\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, logs):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        pass\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(monitor=\"val_categorical_crossentropy\", filepath=\"../resource/model.keras\", save_best_only=True),\n",
    "    keras.callbacks.TensorBoard(log_dir=\"../logs\"),\n",
    "    CustomCallback(),\n",
    "]\n",
    "model.save()\n",
    "keras.models.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 08**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(conv_base, dataset):\n",
    "    features, labels = [], []\n",
    "    for images_batch, labels_batch in dataset:\n",
    "        images_batch = keras.applications.vgg16.preprocess_input(images_batch)\n",
    "        features_batch = conv_base.predict(x=images_batch, verbose=False)\n",
    "        features.append(features_batch)\n",
    "        labels.append(labels_batch)\n",
    "    return np.concatenate(features, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "augmentation_layer = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomZoom(0.1),\n",
    "        keras.layers.RandomRotation(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Rescaling(1 / 255.0)(i)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", strides=1, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(180, 180, 3))\n",
    "i = augmentation_layer(i)\n",
    "x = keras.layers.Rescaling(1 / 255.0)(i)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", strides=1, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "conv_base = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\")\n",
    "new_base_dir, train_dataset, val_dataset, test_dataset = chapter_08.dataset_batches()\n",
    "x_train, y_train = extract_features(conv_base, train_dataset)\n",
    "x_test, y_test = extract_features(conv_base, test_dataset)\n",
    "x_val, y_val = extract_features(conv_base, val_dataset)\n",
    "i = keras.Input(shape=(5, 5, 512))\n",
    "x = keras.layers.Flatten()(i)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "conv_base.trainable = False\n",
    "i = keras.Input(shape=(5, 5, 512))\n",
    "i = augmentation_layer(i)\n",
    "x = keras.applications.vgg16.preprocess_input(i)\n",
    "x = conv_base(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "i = keras.Input(shape=(5, 5, 512))\n",
    "i = augmentation_layer(i)\n",
    "x = keras.applications.vgg16.preprocess_input(i)\n",
    "x = conv_base(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "o = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 09**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = keras.Input(shape=(200, 200, 3))\n",
    "x = keras.layers.Rescaling(1.0 / 255)(i)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "o = keras.layers.Conv2D(filters=4, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.softmax)(x)\n",
    "model = keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "i = keras.Input(shape=(200, 200, 3))\n",
    "x = keras.layers.SeparableConv2D(filters=64, kernel_size=3, strides=2, padding=\"same\", activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation(activation=tf.nn.relu)(x)\n",
    "r = x\n",
    "x = keras.layers.SeparableConv2D(filters=256, kernel_size=3, strides=1, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "r = keras.layers.SeparableConv2D(filters=256, kernel_size=1, strides=2, activation=None)(r)\n",
    "x = keras.layers.add([x, r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
