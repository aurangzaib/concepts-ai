{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Chapter 08**\n",
    "# **Introduction to deep learning for computer vision**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "import importlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# TensorFlow Libraries\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# User Libraries\n",
    "from modules import Chapter_01\n",
    "from modules import Chapter_08\n",
    "from modules import Common\n",
    "\n",
    "# Reload Libraries\n",
    "importlib.reload(Chapter_01)\n",
    "importlib.reload(Chapter_08)\n",
    "importlib.reload(Common)\n",
    "\n",
    "# Check GPU\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "\n",
    "# Module variables\n",
    "batch_size = 2048\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Convolution theory**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <ins />**Convolution layers**\n",
    "  - Dense layers learn patterns of global input feature map\n",
    "  - Conv layers learn patterns of local input patch\n",
    "  - Convolution classification network has two parts:\n",
    "     - Convolution base: Conv2D + Maxpooling\n",
    "     - Logit: Dense\n",
    "  - Convolution base:\n",
    "    - Lower layers extract specific feature maps\n",
    "    - Upper layers extract highly generic feature maps\n",
    "  - Translation invariant patterns\n",
    "    - After learning a pattern once, Conv layer can infer it anywhere in the image\n",
    "  - Spatial hierarchical patterns\n",
    "    - Upper layers learn generic patterns\n",
    "    - Lower layers learn specific patterns\n",
    "  - For problems where object location matters, dense layer is useless\n",
    "  - Dense layer is also called fully connected layer\n",
    "\n",
    "### <ins />**Feature map**\n",
    "  - Height, Width, Channels (H, W, D)\n",
    "  - Feature map size: HxW\n",
    "  - Feature map depth: D\n",
    "  - For larger images, we increase number of layers:\n",
    "    - To increase feature map depth\n",
    "    - To decrease feature map size\n",
    "    - To increase model capacity\n",
    "  - In a convnet\n",
    "    - Feature map depth increases with each layer\n",
    "    - Feature map size decreases with each layer\n",
    "  \n",
    "### <ins />**Input feature map (3D)**\n",
    "  - 28x28x1 matrix input image\n",
    "\n",
    "### <ins />**Filter**\n",
    "  - Depth of output feature map\n",
    "  - 32, 64, etc.\n",
    "\n",
    "### <ins />**Kernel (2D)**\n",
    "  - 3x3 matrix aka convolution kernel / structuring element\n",
    "  - Same kernel is used with all input patches\n",
    "\n",
    "### <ins />**Input patch (2D)**\n",
    "  - 3x3 matrix patch of input feature map\n",
    "\n",
    "### <ins />**Reponse map (1D)**\n",
    "  - 3x1 Tensorproduct of kernel and input patch\n",
    "\n",
    "### <ins />**Output feature map (3D)**\n",
    "  - Combine all response maps into matrix\n",
    "  \n",
    "### <ins />**Convolution operation (sliding window)**\n",
    "  1. Slide the kernel on input feature map\n",
    "  2. Extract input patch\n",
    "  3. Tensor product the kernel and input patch to get response map vector\n",
    "  4. Combine all response map vectors (one per patch) to get output feature map\n",
    "  5. Output map size is less than input map size due to convolution border effect and stride\n",
    "\n",
    "### <ins />**Padding**\n",
    "  - To counter border effect i.e. in order to have output map size equals input map size\n",
    "  - Valid padding\n",
    "    - No padding applied (default)\n",
    "    - Output map size < Input map size\n",
    "  - Same padding\n",
    "    - Padding applied\n",
    "    - Output map size = Input map size\n",
    "    - Padding size depends on kernel size, not on input patch size\n",
    "    - Padding for 3x3 kernel:\n",
    "      - 1x row on top. 1x row on bottom\n",
    "      - 1x column on right. 1x column on left\n",
    "    - Padding for 5x5 kernel:\n",
    "      - 2 rows on top. 2 rows on bottom\n",
    "      - 2 columns on right. 2 columns on left\n",
    "\n",
    "### <ins />**Stride**\n",
    "  - Distance between two consecutive convolution windows\n",
    "  - Not used in classification convnets (see maxpooling)\n",
    "  - Downsampling mechanism\n",
    "  - Stride=1 (default)\n",
    "\n",
    "### <ins />**Maxpooling**\n",
    "  - Max patch: 2x2 matrix of max value of input patch\n",
    "  - Tensorproduct of max patch and input patch\n",
    "  - Used in classification convnets \n",
    "  - Downsampling mechanism\n",
    "\n",
    "### <ins />**Convolution vs Maxpooling vs Avgpooling**\n",
    "  - Maxpooling:\n",
    "    - Kernel=2x2 (pool size)\n",
    "    - Stride=2\n",
    "    - **Kernel uses max value of input patch**\n",
    "    - Feature map size is reduced by **size / 2**\n",
    "  - Avgpooling:\n",
    "    - Kernel=2x2 (pool size)\n",
    "    - Stride=2\n",
    "    - **Kernel uses average value of input patch**\n",
    "    - Feature map size is reduced by **size / 2**\n",
    "  - Convolution:\n",
    "    - Kernel=3x3 (kernel size)\n",
    "    - Stride=1\n",
    "    - **Kernel uses fixed value irrespective of input patch**\n",
    "    - Feature map size is reduced by **size - 2**\n",
    "\n",
    "### <ins />**Why downsample (stride / maxpooling / avgpooling)**\n",
    "  - Reduce number of coefficients and overfit\n",
    "    - Without maxpooling = 61952 coefficients \n",
    "    - With maxpooling = 1152 coefficients  \n",
    "  - Increase channel-to-height/width ratio\n",
    "    - Without maxpooling = 24x24x64\n",
    "    - With maxpooling = 11x11x64\n",
    "\n",
    "### <ins />**Data Augmentation**\n",
    "   - Remix the already available information\n",
    "   - No new information created\n",
    "   - To further reduce overfit, use dropout\n",
    "   - Augmentatiom and dropout layers have no effect during inference\n",
    "\n",
    "### <ins />**Transfer learning**\n",
    "  - Models trained on large dataset (different classes) serve as generic model of visual world\n",
    "  - E.g. Model trained on ImageNet (animals) used as base model for bottle detection\n",
    "  - Deep learning with convet is effective for small dataset due to  transfer learning\n",
    "  - Types of transfer learning: \n",
    "    - Feature extraction\n",
    "    - Fine tuning\n",
    "\n",
    "### <ins />**Feature extraction**\n",
    "  - Take convolution base of another model and add a new fully connected (dense) layer\n",
    "  - Using dense layer from another model **should be avoided**\n",
    "  - New dataset has similar classes:\n",
    "    - Use all layers of convolution base except dense layer\n",
    "  - New dataset has different classes:\n",
    "    - Use upper layers of convolution base\n",
    "  - Types of feature extraction:\n",
    "    - Conv base not part of training:\n",
    "      - Use conv base to extract features once before training\n",
    "      - Feed conv base output to Dense classifier during training\n",
    "      - Data augmentation layer can not be used\n",
    "      - Faster\n",
    "    - Conv base part of training\n",
    "      - Data augmentation layer can be used\n",
    "      - Slower\n",
    "\n",
    "### <ins />**Fine tuning**\n",
    "  - In fine tuning, only few upper layers are frozen \n",
    "  - In feature extractions, all layers are frozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Maxpooling and padding use cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Case-1: No padding. No maxpooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "keras.Model(inputs=inputs, outputs=outputs).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Case-2: With padding. No maxpooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "keras.Model(inputs=inputs, outputs=outputs).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Case-3: No padding. With maxpooling (recommended)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "keras.Model(inputs=inputs, outputs=outputs).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Case-4: Model with padding, with maxpooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "keras.Model(inputs=inputs, outputs=outputs).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Tensorflow dataset api**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Efficient input batch pipeline\n",
    "- Asynchronous data prefetching (fetch new batch while previous batch is being handled by model)\n",
    "- normal vs uniform distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [x for x in range(0, 20)]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "# -----------------------------------------\n",
    "# Shuffle\n",
    "# -----------------------------------------\n",
    "dataset = dataset.shuffle(len(dataset))\n",
    "# -----------------------------------------\n",
    "# Batch\n",
    "# -----------------------------------------\n",
    "dataset = dataset.batch(5)\n",
    "for batch in dataset:\n",
    "    print(\"Original: \", batch)\n",
    "# -----------------------------------------\n",
    "# Reduce\n",
    "# -----------------------------------------\n",
    "reduced = dataset.reduce(initial_state=0, reduce_func=lambda x, y: x + y)\n",
    "print(\"Reduced: \", reduced)\n",
    "# -----------------------------------------\n",
    "# Map\n",
    "# -----------------------------------------\n",
    "dataset = dataset.map(lambda x: x * 0)\n",
    "for batch in dataset:\n",
    "    print(\"Mapped: \", batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Simple convolution network**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = Chapter_08.dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=10, activation=tf.nn.softmax)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model = Chapter_01.compile(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = Chapter_01.train(\n",
    "    x=x_train, y=y_train, model=model, epochs=epochs, batch_size=batch_size, callbacks=Common.callbacks()\n",
    ")\n",
    "Chapter_01.evaluate(x=x_test, y=y_test, model=model)\n",
    "Common.plot(data=[history], labels=[\"Convnet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Kaggle cats-vs-dog dataset**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_base_dir, train_dataset, val_dataset, test_dataset = Chapter_08.dataset_batches()\n",
    "model_dir = \"../resources/models/cats_dogs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Training from scratch without augmentation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu)(inputs)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model = Chapter_01.compile(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Common.callbacks(model_dir=model_dir + \"01_train_scratch.keras\")\n",
    "history = Chapter_01.train_batch(train_dataset, val_dataset, model, callbacks, batch_size=batch_size)\n",
    "Common.plot(data=[history], labels=[\"Scratch\"], start_index=1)\n",
    "Chapter_01.evaluate_batch(test_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Training from scratch with augmentation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_layers():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.layers.RandomFlip(\"horizontal\"),\n",
    "            keras.layers.RandomRotation(0.1),\n",
    "            keras.layers.RandomZoom(0.2),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = get_augmentation_layers()(inputs)  # New\n",
    "x = keras.layers.Rescaling(1.0 / 255)(x)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=2)(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)  # New\n",
    "outputs = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model = Chapter_01.compile(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins />**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Common.callbacks(model_dir=model_dir + \"01_train_scratch.keras\")\n",
    "history = Chapter_01.train_batch(train_dataset, val_dataset, model, callbacks, batch_size=batch_size, epochs=epochs)\n",
    "Common.plot(data=[history], labels=[\"Augmentation\"], start_index=1)\n",
    "Chapter_01.evaluate_batch(test_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Training using feature extraction without augmentation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pretrained convolution base is used for feature extraction\n",
    "2. Extracted features are used as input to Dense classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Convolution base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3),\n",
    ")\n",
    "print(\"Weights: \", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(conv_base, dataset):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(batch_images)\n",
    "        batch_features = conv_base.predict(preprocessed_images, verbose=False)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_labels)\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "\n",
    "train_features, train_labels = extract_features(conv_base, train_dataset)\n",
    "val_features, val_labels = extract_features(conv_base, val_dataset)\n",
    "test_features, test_labels = extract_features(conv_base, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = keras.layers.Flatten()(inputs)\n",
    "x = keras.layers.Dense(units=256, activation=None)(x)  # New\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "outputs = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model = Chapter_01.compile(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Common.callbacks(model_dir=model_dir + \"03_train_feature_extraction.keras\")\n",
    "history = Chapter_01.train_val(\n",
    "    x=train_features,\n",
    "    y=train_labels,\n",
    "    x_val=val_features,\n",
    "    y_val=val_labels,\n",
    "    model=model,\n",
    "    callbacks=callbacks,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Plot history\n",
    "Common.plot(data=[history], labels=[\"Feature extraction 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Training using feature extraction with augmentation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Convolution base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    ")\n",
    "# Previously learned weights on ImageNet will be overwritten if trainable is true\n",
    "# Freeze all layers\n",
    "conv_base.trainable = False\n",
    "print(\"Weights: \", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = get_augmentation_layers()(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)  # New\n",
    "x = conv_base(x)  # New\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(units=256, activation=None)(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "outputs = keras.layers.Dense(units=1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model = Chapter_01.compile(model=model)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Common.callbacks(model_dir=model_dir + \"04_train_feature_extraction.keras\")\n",
    "history = Chapter_01.train_batch(train_dataset, val_dataset, model, callbacks, batch_size=10000, epochs=epochs)\n",
    "Common.plot(data=[history], labels=[\"Feature extraction 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Training using fine tuning**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Convolution base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    ")\n",
    "# Weights of last convolution block will be updated\n",
    "# Finetune the last convolution block\n",
    "for layer in conv_base.layers[0:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Common.callbacks(model_dir=model_dir + \"04_train_feature_extraction.keras\")\n",
    "history = Chapter_01.train_batch(train_dataset, val_dataset, model, callbacks, batch_size=batch_size, epochs=epochs)\n",
    "Common.plot(data=[history], labels=[\"Feature extraction 2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
