{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Francois Chollet (2E, 2021)**\n",
    "# **Deep Learning with Python**\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. What is deep learning?** \n",
    "   \n",
    "1. Keras to train, predict, and evaluate on mnist dataset\n",
    "\n",
    "#### **2. The mathematical building blocks of neural networks**\n",
    "1. Initialize weight and bias\n",
    "2. Find prediction\n",
    "3. Find loss\n",
    "4. Find gradient\n",
    "5. Update weight and bias\n",
    "\n",
    "#### **3. Introduction to Keras and TensorFlow**\n",
    "1. TensorFlow variable and constant\n",
    "2. First order gradient\n",
    "3. Second order gradient\n",
    "4. Linear classifier using TensorFlow\n",
    "5. Linear classifier using Keras - V1\n",
    "6. Linear classifier using Keras - V2\n",
    "\n",
    "#### **4. Getting started with neural networks**\n",
    "1. Common Terminologies\n",
    "2. Binary Classification\n",
    "3. Multiclass Classification\n",
    "4. Scalar Regression\n",
    "5. Feature-wise Normalization\n",
    "6. K-Fold Cross-Validation\n",
    "\n",
    "#### **5. Fundamentals of machine learning**\n",
    "1. White Noise and Zero Channels\n",
    "2. Manifold Hypothesis\n",
    "3. Dataset Split\n",
    "4. Gradient Descent Parameters\n",
    "5. Architecture Priors\n",
    "6. Model Capacity\n",
    "7. Feature Engineering\n",
    "8. Early Stopping\n",
    "9. L1/L2 Regularization\n",
    "10. Dropout\n",
    "\n",
    "#### **6. The universal workflow of machine learning**\n",
    "1. Task Definition\n",
    "2. Model Development\n",
    "3. Model Deployment\n",
    "\n",
    "#### **7. Working with Keras: A deep dive**\n",
    "1. Module Patterns:\n",
    "   1. Keras.Sequential\n",
    "   2. Keras.Model\n",
    "   3. Subclass Keras.Model\n",
    "2. Mixing Module Patterns\n",
    "3. Builtin Training and Evaluation Loops\n",
    "4. Custom Training and Evaluation Loops\n",
    "\n",
    "#### **8. Introduction to deep learning for computer vision**\n",
    "\n",
    "#### **9.  Advanced deep learning for computer vision**\n",
    "\n",
    "#### **10. Deep learning for timeseries**\n",
    "\n",
    "#### **11. Deep learning for text**\n",
    "\n",
    "#### **12. Generative deep learning**\n",
    "\n",
    "#### **13. Best practices for the real world**\n",
    "\n",
    "#### **14. Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Common Concepts**\n",
    "---\n",
    "\n",
    "#### **Terminologies:**\n",
    "1. Sample / Input\n",
    "2. Prediction / Output\n",
    "3. Ground truth / Annotation\n",
    "4. Target\n",
    "5. Loss\n",
    "6. Classes\n",
    "7. Label\n",
    "8. Binary Classification\n",
    "9. Multiclass Classification\n",
    "10. Multilabel Classification\n",
    "11. Scalar regression\n",
    "12. Vector regression\n",
    "13. Batch\n",
    "\n",
    "#### **Layers (tf.keras.layers):**\n",
    "1. (Rank 1) Dense\n",
    "2. (Rank 2) LSTM\n",
    "3. (Rank 3) Conv1D\n",
    "4. (Rank 4) Conv2D\n",
    "\n",
    "#### **Optimizers (tf.keras.optimizers):**\n",
    "1. SGD (with / without momentum)\n",
    "2. RMSprop\n",
    "3. Adam\n",
    "4. Adagrad\n",
    "\n",
    "#### **Loss Functions (tf.keras.losses):**\n",
    "1. CategoricalCrossEntropy\n",
    "2. SparseCategoricalCrossentropy\n",
    "3. BinaryCrossEntropy\n",
    "4. MeanSquaredError (MSE)\n",
    "\n",
    "#### **Metrics (tf.keras.metrics):**\n",
    "1. CategoricalAccuracy\n",
    "2. SparseCategoricalAccuracy\n",
    "3. BinaryAccuracy\n",
    "4. MeanAbsoluteError (MAE)\n",
    "5. Precision\n",
    "6. Recall\n",
    "\n",
    "#### **K-Fold Cross-Validation**\n",
    "- When dataset is small, K-Fold allows to use whole dataset for training as well as validation\n",
    "- Training dataset is divided into K number of folds.\n",
    "- Each fold uses different part of data as validation dataset\n",
    "- In each iteration:\n",
    "  - K-1 partitions are used for training\n",
    "  - 1 partition is used for validation\n",
    "- Validation score is the average of validations of all folds\n",
    "\n",
    "#### **Training Parameters**\n",
    "- **Network Parameters:**\n",
    "  - Weight \n",
    "  - Bias\n",
    "\n",
    "- **Training Parameters:**\n",
    "  - Number of layers\n",
    "  - Learning rate\n",
    "  - Batchsize\n",
    "  - Optimizer\n",
    "  - Epoch\n",
    "\n",
    "#### **Training Priors**\n",
    "  - Dataset\n",
    "  - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
